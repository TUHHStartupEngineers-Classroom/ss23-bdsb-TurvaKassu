[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "# Data Science at TUHH ------------------------------------------------------\n# SALES ANALYSIS ----\n\n# 1.0 Load libraries ----\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(lubridate)\n\n# 2.0 Importing Files ----\nbikes_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\bikes.xlsx\")\nbikeshops_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\bikeshops.xlsx\")\norderlines_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\orderlines.xlsx\")\n\n#> New names:\n#> • `` -> `...1`\n\n# 3.0 Examining Data ----\nbikes_tbl  %>% head(5)\n\n\n\n  \n\n\nbikeshops_tbl %>% head(5)\n\n\n\n  \n\n\norderlines_tbl %>% head(5)\n\n\n\n  \n\n\n# 4.0 Joining Data ----\nmerged_orderlines <- orderlines_tbl %>% \n  left_join(bikes_tbl, by = c(\"product.id\" =  \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\n\n# 5.0 Wrangling Data ----\nbike_orderlines_wrangled_tbl <- merged_orderlines %>%\n  # 5.1 Separate category name\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") %>%\n  mutate(total.price = price * quantity) %>%\n  select(-ends_with(\".id\")) %>%\n  bind_cols(merged_orderlines %>% select(order.id)) %>%\n  select(order.id, contains(\"order\"), contains(\"model\"), contains(\"category\"),\n         price, quantity, total.price,\n         everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\nbike_orderlines_wrangled_tbl %>% head(5)\n\n\n\n  \n\n\n# 6.0 Business Insights ----\n\n# 6.1 Sales by Year and State ----\n\n# Step 1 - Manipulate\nsales_by_year_date <- bike_orderlines_wrangled_tbl %>%\n  select(\"order_date\", \"total_price\", \"state\") %>%\n  mutate(year_column = year(order_date)) %>%\n  group_by(year_column, state)%>%\n  summarise(sales = sum(total_price))\n\n#> `summarise()` has grouped output by 'year_column'. You can override using the\n#> `.groups` argument.\n\n  sales_by_year_date\n\n\n\n  \n\n\n# Step 2 - Visualize\nggplot(sales_by_year_date, aes(x = year_column, y = sales, fill = factor(state))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~state, ncol = 3) +\n  labs(x = \"Year\", y = \"Sales\", title = \"Total Price by Year and State\") +\n  scale_fill_discrete(name = \"sales\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Challenge:\n\nGetting Instagam followers of single user. First we need to get the account id\n\n\n#First lets load all necessary libraries\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n#> \n#> Attaching package: 'rvest'\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     guess_encoding\n\nlibrary(xopen)     # Quickly opening URLs\nlibrary(jsonlite)  # converts JSON files to R objects\n\n#> \n#> Attaching package: 'jsonlite'\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     flatten\n\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(httr)      # http requests\n\n# Getting user id for \"Kassu_1999\"\nurl <- \"https://instagram47.p.rapidapi.com/get_user_id\"\n\nqueryString <- list(username = \"kassu_1999\")\n\nresponse <- VERB(\"GET\", url, query = queryString, add_headers('X-RapidAPI-Key' = '7d3612512fmsh3b8eaaed9d17621p163f47jsn474741263db5', 'X-RapidAPI-Host' = 'instagram47.p.rapidapi.com'), content_type(\"application/octet-stream\"))\n\nuser_id <- content(response, as=\"parsed\")$user_id\nuser_id\n\n#> NULL\n\n# Getting followers of user with user_id\nurl <- \"https://instagram47.p.rapidapi.com/user_followers\"\n\nqueryString <- list(userid = user_id)\n\nresponse <- VERB(\"GET\", url, query = queryString, add_headers('X-RapidAPI-Key' = '7d3612512fmsh3b8eaaed9d17621p163f47jsn474741263db5', 'X-RapidAPI-Host' = 'instagram47.p.rapidapi.com'), content_type(\"application/octet-stream\"))\n\n# Getting response to tibble\nresponse_content <- content(response, as = \"text\")\n\n#> No encoding supplied: defaulting to UTF-8.\n\nresponse_json <- fromJSON(response_content)\nfollowers <- response_json$body$edges\nfollowers_tbl <- head(as_tibble(followers), 10)\nfollowers_tbl\n\n\n\n  \n\n\n\nPart 2: Scraping data from https://www.rosebikes.de/\n\n# Setting home parameters\nurl_home <- \"https://www.rosebikes.de/fahrräder\"\n\nhtml_home <- read_html(url_home)\n\n# Getting bike families\nbike_families_tbl <- html_home %>%\n  html_nodes(\".catalog-navigation__link\") %>%\n  html_attr('title') %>%\n  discard(.p = ~stringr::str_detect(.x,\"Sale|Bike Finder|Schnell verfügbare Bikes\")) %>%\n  enframe(name = \"position\", value = \"family_class\")\n\n# Gettin url's from same elements and adding domain\nbike_url_tbl <- html_home %>%\n  html_nodes(\".catalog-navigation__link\") %>%\n  html_attr('href') %>%\n  discard(.p = ~stringr::str_detect(.x,\"Sale|Bike Finder|Schnell verfügbare Bikes\")) %>%\n  enframe(name = \"position\", value = \"url\") %>%\n  mutate(\n    url = glue(\"https://www.rosebikes.de{url}\") )\n  \n\n# Joining two tibbles\nbike_families_url_tbl <- left_join(bike_families_tbl, bike_url_tbl)\n\n#> Joining with `by = join_by(position)`\n\n# Get url from first bike category\nmtb_category_url <- bike_families_url_tbl$url[1]\n\n# Get html of mtb category bikes\nmtb_html <- read_html(mtb_category_url)\n\n# Scrape price data from mtb category bikes\nmtb_price_tbl <- mtb_html %>%\n  html_nodes(\".catalog-category-bikes__price-title\") %>%\n  html_text() %>%\n  str_replace(\"^[^0-9]+\", \"\") %>%\n  str_replace(\"[^0-9]+$\", \"\") %>%\n  \n  enframe(name = \"position\", value = \"price\")\n\n# Scrape name data from mtb category bikes\nmtb_name_tbl <- mtb_html %>%\n  html_nodes(\"h4.basic-headline__title\") %>%\n  html_text() %>%\n  enframe(name = \"position\", value = \"name\")\n\n# Join the tibbles\nmtb_bikes_data_tbl <- left_join(mtb_name_tbl, mtb_price_tbl)\n\n#> Joining with `by = join_by(position)`\n\nmtb_bikes_data_tbl"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Challenge:\n\n# Setting up libraries\nlibrary(vroom)\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ readr::col_character()   masks vroom::col_character()\n#> ✖ readr::col_date()        masks vroom::col_date()\n#> ✖ readr::col_datetime()    masks vroom::col_datetime()\n#> ✖ readr::col_double()      masks vroom::col_double()\n#> ✖ readr::col_factor()      masks vroom::col_factor()\n#> ✖ readr::col_guess()       masks vroom::col_guess()\n#> ✖ readr::col_integer()     masks vroom::col_integer()\n#> ✖ readr::col_logical()     masks vroom::col_logical()\n#> ✖ readr::col_number()      masks vroom::col_number()\n#> ✖ readr::col_skip()        masks vroom::col_skip()\n#> ✖ readr::col_time()        masks vroom::col_time()\n#> ✖ readr::cols()            masks vroom::cols()\n#> ✖ readr::date_names_lang() masks vroom::date_names_lang()\n#> ✖ readr::default_locale()  masks vroom::default_locale()\n#> ✖ dplyr::filter()          masks stats::filter()\n#> ✖ readr::fwf_cols()        masks vroom::fwf_cols()\n#> ✖ readr::fwf_empty()       masks vroom::fwf_empty()\n#> ✖ readr::fwf_positions()   masks vroom::fwf_positions()\n#> ✖ readr::fwf_widths()      masks vroom::fwf_widths()\n#> ✖ dplyr::lag()             masks stats::lag()\n#> ✖ readr::locale()          masks vroom::locale()\n#> ✖ readr::output_column()   masks vroom::output_column()\n#> ✖ readr::problems()        masks vroom::problems()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(data.table)\n\n#> \n#> Attaching package: 'data.table'\n#> \n#> The following objects are masked from 'package:lubridate':\n#> \n#>     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#>     yday, year\n#> \n#> The following objects are masked from 'package:dplyr':\n#> \n#>     between, first, last\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     transpose\n\nlibrary(dplyr)\n\nLet’s import the reduced data to R with vroom\n\n#Importing data\ncol_types <- list(\n  patent_id = col_character(),\n  id = col_character(),\n  assignee_id = col_character(),\n  type = col_integer(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_integer(),\n  organization = col_character(),\n  mainclass_id = col_character(),\n  sequence = col_integer()\n)\n\npatent_tbl <- vroom(\n            file       = \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Patent_data_reduced\\\\patent.tsv\", \n            delim      = \"\\t\", \n            col_types  = col_types,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\n#> Warning: The following named parsers don't match the column names: patent_id,\n#> assignee_id, type, organization, mainclass_id, sequence\n\npatent_assignee_tbl <- vroom(\n            file = \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Patent_data_reduced\\\\patent_assignee.tsv\",\n            delim      = \"\\t\", \n            col_types  = col_types,\n            na         = c(\"\", \"NA\", \"NULL\")\n            )\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> date, num_claims, organization, mainclass_id, sequence\n\nassignee_tbl <- vroom(\n            file = \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Patent_data_reduced\\\\assignee.tsv\",\n            delim      = \"\\t\", \n            col_types  = col_types,\n            na         = c(\"\", \"NA\", \"NULL\")\n            )\n\n#> Warning: The following named parsers don't match the column names: patent_id,\n#> assignee_id, date, num_claims, mainclass_id, sequence\n\nuspc_tbl <- vroom(\n            file = \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Patent_data_reduced\\\\uspc.tsv\",\n            delim      = \"\\t\", \n            col_types  = col_types,\n            na         = c(\"\", \"NA\", \"NULL\")\n            )\n\n#> Warning: The following named parsers don't match the column names: id,\n#> assignee_id, type, date, num_claims, organization\n\n# Combine tibbles\ncomplete_patent_tbl <- left_join(\n  patent_tbl, patent_assignee_tbl, by = c(\"id\" = \"patent_id\")) %>%\n  left_join(assignee_tbl, by = c(\"assignee_id\" = \"id\")) %>%\n  left_join(uspc_tbl, by = c(\"id\" = \"patent_id\"))\n\n#> Warning in left_join(., uspc_tbl, by = c(id = \"patent_id\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n#> ℹ Row 2 of `x` matches multiple rows in `y`.\n#> ℹ Row 109363 of `y` matches multiple rows in `x`.\n#> ℹ If a many-to-many relationship is expected, set `relationship =\n#>   \"many-to-many\"` to silence this warning.\n\n\nTransform tibble into data.table and excluding NA values for organization\n\npatent_dt <- as.data.table(complete_patent_tbl)[!is.na(organization)][!is.na(mainclass_id)]\n\nQuestion 1: Which organizations posses most number of patents?\n\nnumber_of_patents <- patent_dt[, .N, by=organization] %>%\n  .[order(-N)] %>%\n  .[1:10]\nprint(number_of_patents)\n\n#>                                    organization     N\n#>  1: International Business Machines Corporation 19056\n#>  2:               Samsung Electronics Co., Ltd. 14523\n#>  3:                      Canon Kabushiki Kaisha  9467\n#>  4:                            Sony Corporation  8372\n#>  5:                       QUALCOMM Incorporated  7322\n#>  6:                       Microsoft Corporation  7195\n#>  7:                    Kabushiki Kaisha Toshiba  6957\n#>  8:                                 Google Inc.  6082\n#>  9:                         LG Electronics Inc.  5694\n#> 10:                       Panasonic Corporation  5641\n\n\nQuestion 2: Companies with most patents in August 2014.\nFirst we need to add date column to previous dt manipulation\n\nnumber_of_patents_august <- patent_dt[year(date) == 2014 & month(date) == 8, .N, by=organization] %>%\n  .[order(-N)] %>%\n  .[1:10]\nprint(number_of_patents)\n\n#>                                    organization     N\n#>  1: International Business Machines Corporation 19056\n#>  2:               Samsung Electronics Co., Ltd. 14523\n#>  3:                      Canon Kabushiki Kaisha  9467\n#>  4:                            Sony Corporation  8372\n#>  5:                       QUALCOMM Incorporated  7322\n#>  6:                       Microsoft Corporation  7195\n#>  7:                    Kabushiki Kaisha Toshiba  6957\n#>  8:                                 Google Inc.  6082\n#>  9:                         LG Electronics Inc.  5694\n#> 10:                       Panasonic Corporation  5641\n\n\nQuestion 3: What is the most innovative tech industry?\nSolve the main class of most number of patents\n\n# Get the top10 orgs with most patents\ntop10_orgs <- patent_dt[, .N, by=organization] %>%\n  .[order(-N)] %>%\n  .[1:10] %>%\n  select(organization)\n\n# Only include rows with orgs from top10_orgs and group by mainclass_id\ntop5_mainclasses <- patent_dt[organization %in% top10_orgs$organization, \n                              .N, by=mainclass_id] %>%\n                    .[order(-N)] %>%\n                    .[1:5]\n\nprint(top5_mainclasses)\n\n#>    mainclass_id    N\n#> 1:          257 7979\n#> 2:          455 6191\n#> 3:          370 5483\n#> 4:          348 4113\n#> 5:          709 4018"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Reading data into tibble\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(vroom)\n\n#> \n#> Attaching package: 'vroom'\n#> \n#> The following objects are masked from 'package:readr':\n#> \n#>     as.col_spec, col_character, col_date, col_datetime, col_double,\n#>     col_factor, col_guess, col_integer, col_logical, col_number,\n#>     col_skip, col_time, cols, cols_condense, cols_only, date_names,\n#>     date_names_lang, date_names_langs, default_locale, fwf_cols,\n#>     fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n#>     problems, spec\n\nlibrary(readxl)\nlibrary(readr)\nlibrary(scales)\n\n#> \n#> Attaching package: 'scales'\n#> \n#> The following object is masked from 'package:vroom':\n#> \n#>     col_factor\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     discard\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     col_factor\n\ncol_types <- list(\n  location = col_character(),\n  date = col_date(\"YYYY-MM-DD\"),\n  total_cases = col_integer(11)\n)\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\") %>%\n  as_tibble()\n\n#> Rows: 311447 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFiltering rows with cases from Spain, France, Germany, UK, USA\n\nselected_countries <- c(\"Spain\", \"France\", \"United Kingdom\", \"United States\", \"Germany\")\ncovid_data_filtered_tbl <- covid_data_tbl %>%\n  filter(!is.na(\"continent\"), covid_data_tbl$location %in% selected_countries)\n\nSelecting columns that we need: Location, date, total_cases\n\nwrangled_covid_data <- covid_data_filtered_tbl %>%\n  select(location, date, total_cases)\n\nPlot it with ggplot2\n\ndesired_colors <- c(\"Spain\" = \"red\", \"France\" = \"blue\", \"United Kingdom\" = \"green\", \"United States\" = \"orange\", \"Germany\" = \"purple\")\nggplot(wrangled_covid_data, aes(x = date, y = total_cases, color = location)) +\n  geom_line() +\n  scale_color_manual(values = desired_colors) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"1 year\") +\n  labs(x = \"Date\", y = \"Total Cases\") +\n  ggtitle(\"Total Cases Over Time in Desired Locations\")\n\n#> Warning: Removed 83 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\n\n\nChallenge 2:\nLets merge the map data in\n\nworld <- map_data(\"world\") %>%\n  distinct(region, .keep_all = TRUE)\n\n\nwrangled_covid_data2 <- covid_data_tbl %>%\n  filter(!is.na(location)) %>%\n  select(location, date, total_cases, total_deaths) %>% \n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location)) %>%\n  group_by(location) %>%\n  slice_max(order_by = total_cases, n = 1) %>%\n  ungroup() %>%\n  distinct(location, .keep_all = TRUE) %>%\n  mutate(mortality = total_deaths / total_cases) %>%\n  rename(region = location)\n\n  \n  merged_data <- merge(wrangled_covid_data2, world, \n                       by = \"region\", all.x = TRUE)\n\nNow we are ready to plot the value on a map\n\nggplot(merged_data) +\n  geom_map(map = world,\n           aes(map_id = region, fill = mortality),\n           color = \"black\") +\n  scale_fill_gradient(low = \"blue\", high = \"red\", na.value = \"gray\", \n                      limits = c(0.001, 0.05) ) +\n  labs(title = \"COVID-19 mortality rate on Heat Map\") +\n  coord_map() +\n  theme_bw()"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Challenge",
    "section": "",
    "text": "Finally learned how to use this"
  },
  {
    "objectID": "Tidyverse/Challenge.html",
    "href": "Tidyverse/Challenge.html",
    "title": "MyLabJournal",
    "section": "",
    "text": "# Data Science at TUHH ------------------------------------------------------\n# SALES ANALYSIS ----\n\n# 1.0 Load libraries ----\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(lubridate)\n\n# 2.0 Importing Files ----\nbikes_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\bikes.xlsx\")\nbikeshops_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\bikeshops.xlsx\")\norderlines_tbl <- read_excel(\n  \"C:\\\\Users\\\\35844\\\\ML\\\\ss23-bdsb-TurvaKassu\\\\Tidyverse\\\\orderlines.xlsx\")\n\nNew names:\n• `` -> `...1`\n\n# 3.0 Examining Data ----\nbikes_tbl  %>% head(5)\n\n# A tibble: 5 × 9\n  bike.id model     model.year frame.material weight price category gender url  \n    <dbl> <chr>          <dbl> <chr>           <dbl> <dbl> <chr>    <chr>  <chr>\n1    2875 Aeroad C…       2020 carbon           7.6   4579 Road - … unisex http…\n2    2873 Aeroad C…       2020 carbon           7.27  6919 Road - … unisex http…\n3    2874 Aeroad C…       2020 carbon           7.1   6429 Road - … unisex http…\n4    2876 Aeroad C…       2020 carbon           7.73  5069 Road - … unisex http…\n5    2877 Aeroad C…       2020 carbon           7.83  3609 Road - … unisex http…\n\nbikeshops_tbl %>% head(5)\n\n# A tibble: 5 × 5\n  bikeshop.id name                location                          lat   lng\n        <dbl> <chr>               <chr>                           <dbl> <dbl>\n1           1 Zum Goldenen Lenker Berlin, Berlin                   52.5 13.4 \n2           2 AlexandeRad         Hamburg, Hamburg                 53.6 10.0 \n3           3 Fahrradladen 16     Munich, Bavaria                  48.2 11.6 \n4           4 Bikestation Köln    Cologne, North Rhine-Westphalia  50.9  6.95\n5           5 Montimare           Frankfurt, Hesse                 50.1  8.68\n\norderlines_tbl %>% head(5)\n\n# A tibble: 5 × 7\n  ...1  order.id order.line order.date          customer.id product.id quantity\n  <chr>    <dbl>      <dbl> <dttm>                    <dbl>      <dbl>    <dbl>\n1 1            1          1 2015-01-07 00:00:00           2       2681        1\n2 2            1          2 2015-01-07 00:00:00           2       2411        1\n3 3            2          1 2015-01-10 00:00:00          10       2629        1\n4 4            2          2 2015-01-10 00:00:00          10       2137        1\n5 5            3          1 2015-01-10 00:00:00           6       2367        1\n\n# 4.0 Joining Data ----\nmerged_orderlines <- orderlines_tbl %>% \n  left_join(bikes_tbl, by = c(\"product.id\" =  \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\n\n# 5.0 Wrangling Data ----\nbike_orderlines_wrangled_tbl <- merged_orderlines %>%\n  # 5.1 Separate category name\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") %>%\n  mutate(total.price = price * quantity) %>%\n  select(-ends_with(\".id\")) %>%\n  bind_cols(merged_orderlines %>% select(order.id)) %>%\n  select(order.id, contains(\"order\"), contains(\"model\"), contains(\"category\"),\n         price, quantity, total.price,\n         everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\nbike_orderlines_wrangled_tbl %>% head(5)\n\n# A tibble: 5 × 19\n  order_id order_line order_date          model        model_year category price\n     <dbl>      <dbl> <dttm>              <chr>             <dbl> <chr>    <dbl>\n1        1          1 2015-01-07 00:00:00 Spectral CF…       2021 Mountai…  3119\n2        1          2 2015-01-07 00:00:00 Ultimate CF…       2020 Road - …  5359\n3        2          1 2015-01-10 00:00:00 Neuron CF 8        2021 Mountai…  2729\n4        2          2 2015-01-10 00:00:00 Speedmax CF…       2019 Road - …  1749\n5        3          1 2015-01-10 00:00:00 Stitched 36…       2020 Mountai…  1219\n# ℹ 12 more variables: quantity <dbl>, total_price <dbl>, `___1` <chr>,\n#   frame_material <chr>, weight <dbl>, gender <chr>, url <chr>,\n#   bikeshop <chr>, city <chr>, state <chr>, lat <dbl>, lng <dbl>\n\n# 6.0 Business Insights ----\n\n# 6.1 Sales by Year and State ----\n\n# Step 1 - Manipulate\nsales_by_year_date <- bike_orderlines_wrangled_tbl %>%\n  select(\"order_date\", \"total_price\", \"state\") %>%\n  mutate(year_column = year(order_date)) %>%\n  group_by(year_column, state)%>%\n  summarise(sales = sum(total_price))\n\n`summarise()` has grouped output by 'year_column'. You can override using the\n`.groups` argument.\n\n  sales_by_year_date\n\n# A tibble: 60 × 3\n# Groups:   year_column [5]\n   year_column state                           sales\n         <dbl> <chr>                           <dbl>\n 1        2015 Baden-Württemberg             1031924\n 2        2015 Bavaria                       1301461\n 3        2015 Berlin                          95853\n 4        2015 Bremen                        1395912\n 5        2015 Hamburg                        423090\n 6        2015 Hesse                          308609\n 7        2015 Lower Saxony                   584386\n 8        2015 Mecklenburg-Western Pomerania  222003\n 9        2015 North Rhine-Westphalia        3735092\n10        2015 Saxony                         238371\n# ℹ 50 more rows\n\n# Step 2 - Visualize\nggplot(sales_by_year_date, aes(x = year_column, y = sales, fill = factor(state))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~state, ncol = 3) +\n  labs(x = \"Year\", y = \"Sales\", title = \"Total Price by Year and State\") +\n  scale_fill_discrete(name = \"sales\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  }
]